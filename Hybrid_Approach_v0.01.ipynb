{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid Approach V0.01\n",
    "\n",
    "This document records the process to implement the first simple version of hybrid approach based on G.B.'s approach.\n",
    "\n",
    "## Auto encoder decoder\n",
    "This subsetion describes how to design an auto encoder decoder to extract features of data.\n",
    "\n",
    "### What is auto encoder decoder ?\n",
    "Auto encoder decoder is a special artificial neural network that tranlate input data and ouput the same/similar data. Because the there is no information lost in the translating process, we can use the data inthe middle layer as the feathures of the input data.\n",
    "\n",
    "When middle layer's hidden variables are less than input variables, auto encoder decoder compresses the data.\n",
    "When middle layer's hidden variables are more than input variables, auto encoder decoder represents data sparsely.\n",
    "\n",
    "#### Auto encoder decoder test\n",
    "##### Test data\n",
    "   Test data comes from a simple function. \n",
    "+ Generate feature vector randomly\n",
    "+ Generate observation data\n",
    "[v1,v2,...,vn]   ==>   [v1,((v1+v2)/2),v2,((v2+v3)/2),...,vn] and then max min normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.19475819  0.77058232  0.87010047]\n",
      " [ 0.9065282   0.89872616  0.01308841]\n",
      " [ 0.34570973  0.47027361  0.4906416 ]\n",
      " ..., \n",
      " [ 0.54165801  0.85655742  0.73898851]\n",
      " [ 0.64968321  0.50514054  0.20407222]\n",
      " [ 0.04361496  0.73136389  0.14377273]]\n",
      "Variable containing:\n",
      " 1.9476e-01  4.8267e-01  7.7058e-01  8.2034e-01  8.7010e-01\n",
      " 9.0653e-01  9.0263e-01  8.9873e-01  4.5591e-01  1.3088e-02\n",
      " 3.4571e-01  4.0799e-01  4.7027e-01  4.8046e-01  4.9064e-01\n",
      "                             â‹®                              \n",
      " 5.4166e-01  6.9911e-01  8.5656e-01  7.9777e-01  7.3899e-01\n",
      " 6.4968e-01  5.7741e-01  5.0514e-01  3.5461e-01  2.0407e-01\n",
      " 4.3615e-02  3.8749e-01  7.3136e-01  4.3757e-01  1.4377e-01\n",
      "[torch.FloatTensor of size 100000x5]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import random\n",
    "import torch\n",
    "\n",
    "#input dimension\n",
    "D = 3\n",
    "#input number\n",
    "N = 100000\n",
    "\n",
    "\n",
    "feature = random.rand(N,D)\n",
    "\n",
    "print(feature)\n",
    "\n",
    "\n",
    "def transfer(input):\n",
    "    n,dim   = input.shape\n",
    "    new_dim = dim*2-1\n",
    "    output  = np.zeros((n,new_dim))\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(new_dim):\n",
    "            if j%2 == 0:\n",
    "                output[i][j] = input[i][int(j/2)]\n",
    "            else:\n",
    "                output[i][j] = ((input[i][int(j/2)]+input[i][int(j/2)+1])/2)\n",
    "    return output\n",
    "\n",
    "np_data   = transfer(feature)\n",
    "data      = torch.FloatTensor(np_data)\n",
    "data      = torch.autograd.Variable(data)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### auto encoder decoder structure design\n",
    "Now, we just use some simple structure.\n",
    "      \n",
    "The structure works!\n",
    "The \"works\" mean just works! But the result is bad! The good thing is that we can start now. The bad thing is that the structure need to be re-designed!\n",
    "\n",
    "TODO: use practical data and design new auto encoder decoder structrue. Quite importance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simple_endecoder (\n",
      "  (in1): Linear (5 -> 10)\n",
      "  (in2): Linear (10 -> 3)\n",
      "  (out1): Linear (3 -> 10)\n",
      "  (out2): Linear (10 -> 5)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class simple_endecoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(simple_endecoder,self).__init__()\n",
    "        #linear\n",
    "        self.in1  = nn.Linear(5,10)\n",
    "        self.in2  = nn.Linear(10,3)\n",
    "\n",
    "        self.out1 = nn.Linear(3,10)\n",
    "        self.out2 = nn.Linear(10,5)\n",
    "            \n",
    "    def forward(self,x):\n",
    "        x = self.in1(x)\n",
    "        x = self.in2(x)\n",
    "\n",
    "        x = self.out1(x)\n",
    "        x = self.out2(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "net       = simple_endecoder()\n",
    "print(net)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print initial parameters:\n",
      "Parameter containing:\n",
      " 0.0739 -0.3110  0.4376 -0.1562 -0.0179\n",
      "-0.2952  0.3878 -0.4344 -0.1913 -0.0279\n",
      "-0.3822 -0.2136 -0.4224  0.0113 -0.4258\n",
      "-0.1513  0.4441  0.2813  0.3158  0.2699\n",
      "-0.4375 -0.3381 -0.3325 -0.2684  0.1049\n",
      " 0.4400 -0.1166  0.3623  0.3031  0.0531\n",
      "-0.3310 -0.4216  0.1247  0.3781 -0.2407\n",
      "-0.3880  0.4385 -0.1115  0.4035 -0.2945\n",
      "-0.1649 -0.3810 -0.1165 -0.3391 -0.1641\n",
      "-0.4268  0.2517  0.3613  0.1369 -0.0570\n",
      "[torch.FloatTensor of size 10x5]\n",
      "\n",
      "Parameter containing:\n",
      "-0.3540\n",
      "-0.3228\n",
      "-0.0770\n",
      "-0.1696\n",
      " 0.1735\n",
      " 0.2130\n",
      " 0.3497\n",
      " 0.1850\n",
      "-0.3522\n",
      "-0.1141\n",
      "[torch.FloatTensor of size 10]\n",
      "\n",
      "Parameter containing:\n",
      "-0.2097  0.0041  0.0264  0.0751 -0.1694 -0.1477  0.2190 -0.0362  0.1562  0.0253\n",
      "-0.0195  0.0137  0.2168  0.1241  0.2493  0.1618  0.0559 -0.0275  0.1287 -0.1708\n",
      "-0.0345  0.2716 -0.2889 -0.1978  0.1139 -0.0299 -0.2597  0.0279  0.2358  0.2660\n",
      "[torch.FloatTensor of size 3x10]\n",
      "\n",
      "Parameter containing:\n",
      " 0.1313\n",
      " 0.1911\n",
      "-0.1688\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Parameter containing:\n",
      " 0.2495 -0.0974 -0.5631\n",
      " 0.2982 -0.3789 -0.0317\n",
      "-0.3555  0.3909  0.1170\n",
      "-0.0769  0.1716  0.0361\n",
      "-0.0409  0.1704  0.4671\n",
      " 0.2370  0.2347  0.3840\n",
      "-0.4435  0.3343 -0.2005\n",
      " 0.3165 -0.0846 -0.3833\n",
      " 0.3256  0.4221  0.4224\n",
      "-0.3365 -0.3635 -0.4368\n",
      "[torch.FloatTensor of size 10x3]\n",
      "\n",
      "Parameter containing:\n",
      "-0.3495\n",
      "-0.4476\n",
      "-0.0137\n",
      "-0.1503\n",
      "-0.0879\n",
      "-0.0892\n",
      " 0.1816\n",
      "-0.5279\n",
      " 0.2223\n",
      "-0.2078\n",
      "[torch.FloatTensor of size 10]\n",
      "\n",
      "Parameter containing:\n",
      " 0.2402  0.1501  0.0174 -0.0126 -0.2817  0.0477 -0.1466  0.2529  0.1419  0.0262\n",
      " 0.1871 -0.3029 -0.0042 -0.1429 -0.0663  0.1194  0.0665  0.1712  0.2073 -0.0864\n",
      " 0.0650  0.1184 -0.2961  0.1040  0.2639  0.1521 -0.0522 -0.3071  0.1140 -0.0851\n",
      "-0.2969 -0.0624 -0.0053 -0.1419  0.0372 -0.0165  0.1538  0.1966 -0.0250 -0.0038\n",
      "-0.0371  0.2694  0.0408  0.2683 -0.1875  0.0064 -0.1699  0.0758 -0.2760  0.1632\n",
      "[torch.FloatTensor of size 5x10]\n",
      "\n",
      "Parameter containing:\n",
      " 0.1425\n",
      " 0.0747\n",
      " 0.2685\n",
      "-0.2711\n",
      " 0.0110\n",
      "[torch.FloatTensor of size 5]\n",
      "\n",
      "[1] loss: 0.351\n",
      "[2] loss: 0.347\n",
      "[3] loss: 0.343\n",
      "[4] loss: 0.339\n",
      "[5] loss: 0.334\n",
      "[6] loss: 0.330\n",
      "[7] loss: 0.327\n",
      "[8] loss: 0.323\n",
      "[9] loss: 0.319\n",
      "[10] loss: 0.315\n",
      "[11] loss: 0.312\n",
      "[12] loss: 0.308\n",
      "[13] loss: 0.304\n",
      "[14] loss: 0.301\n",
      "[15] loss: 0.298\n",
      "[16] loss: 0.294\n",
      "[17] loss: 0.291\n",
      "[18] loss: 0.288\n",
      "[19] loss: 0.284\n",
      "[20] loss: 0.281\n",
      "[21] loss: 0.278\n",
      "[22] loss: 0.275\n",
      "[23] loss: 0.272\n",
      "[24] loss: 0.269\n",
      "[25] loss: 0.266\n",
      "[26] loss: 0.263\n",
      "[27] loss: 0.261\n",
      "[28] loss: 0.258\n",
      "[29] loss: 0.255\n",
      "[30] loss: 0.252\n",
      "[31] loss: 0.250\n",
      "[32] loss: 0.247\n",
      "[33] loss: 0.244\n",
      "[34] loss: 0.242\n",
      "[35] loss: 0.239\n",
      "[36] loss: 0.237\n",
      "[37] loss: 0.234\n",
      "[38] loss: 0.232\n",
      "[39] loss: 0.230\n",
      "[40] loss: 0.227\n",
      "[41] loss: 0.225\n",
      "[42] loss: 0.223\n",
      "[43] loss: 0.220\n",
      "[44] loss: 0.218\n",
      "[45] loss: 0.216\n",
      "[46] loss: 0.214\n",
      "[47] loss: 0.212\n",
      "[48] loss: 0.210\n",
      "[49] loss: 0.208\n",
      "[50] loss: 0.206\n",
      "[51] loss: 0.203\n",
      "[52] loss: 0.201\n",
      "[53] loss: 0.199\n",
      "[54] loss: 0.198\n",
      "[55] loss: 0.196\n",
      "[56] loss: 0.194\n",
      "[57] loss: 0.192\n",
      "[58] loss: 0.190\n",
      "[59] loss: 0.188\n",
      "[60] loss: 0.186\n",
      "[61] loss: 0.185\n",
      "[62] loss: 0.183\n",
      "[63] loss: 0.181\n",
      "[64] loss: 0.179\n",
      "[65] loss: 0.178\n",
      "[66] loss: 0.176\n",
      "[67] loss: 0.174\n",
      "[68] loss: 0.173\n",
      "[69] loss: 0.171\n",
      "[70] loss: 0.169\n",
      "[71] loss: 0.168\n",
      "[72] loss: 0.166\n",
      "[73] loss: 0.165\n",
      "[74] loss: 0.163\n",
      "[75] loss: 0.162\n",
      "[76] loss: 0.160\n",
      "[77] loss: 0.159\n",
      "[78] loss: 0.157\n",
      "[79] loss: 0.156\n",
      "[80] loss: 0.154\n",
      "[81] loss: 0.153\n",
      "[82] loss: 0.152\n",
      "[83] loss: 0.150\n",
      "[84] loss: 0.149\n",
      "[85] loss: 0.148\n",
      "[86] loss: 0.146\n",
      "[87] loss: 0.145\n",
      "[88] loss: 0.144\n",
      "[89] loss: 0.142\n",
      "[90] loss: 0.141\n",
      "[91] loss: 0.140\n",
      "[92] loss: 0.139\n",
      "[93] loss: 0.138\n",
      "[94] loss: 0.136\n",
      "[95] loss: 0.135\n",
      "[96] loss: 0.134\n",
      "[97] loss: 0.133\n",
      "[98] loss: 0.132\n",
      "[99] loss: 0.131\n",
      "[100] loss: 0.130\n",
      "[1] loss: 0.129\n",
      "[2] loss: 0.133\n",
      "[3] loss: 0.133\n",
      "[4] loss: 0.132\n",
      "[5] loss: 0.132\n",
      "[6] loss: 0.131\n",
      "[7] loss: 0.131\n",
      "[8] loss: 0.130\n",
      "[9] loss: 0.130\n",
      "[10] loss: 0.128\n",
      "[11] loss: 0.127\n",
      "[12] loss: 0.127\n",
      "[13] loss: 0.126\n",
      "[14] loss: 0.126\n",
      "[15] loss: 0.125\n",
      "[16] loss: 0.125\n",
      "[17] loss: 0.124\n",
      "[18] loss: 0.124\n",
      "[19] loss: 0.123\n",
      "[20] loss: 0.123\n",
      "[21] loss: 0.122\n",
      "[22] loss: 0.122\n",
      "[23] loss: 0.122\n",
      "[24] loss: 0.121\n",
      "[25] loss: 0.121\n",
      "[26] loss: 0.120\n",
      "[27] loss: 0.120\n",
      "[28] loss: 0.120\n",
      "[29] loss: 0.119\n",
      "[30] loss: 0.119\n",
      "[31] loss: 0.118\n",
      "[32] loss: 0.118\n",
      "[33] loss: 0.118\n",
      "[34] loss: 0.117\n",
      "[35] loss: 0.117\n",
      "[36] loss: 0.116\n",
      "[37] loss: 0.116\n",
      "[38] loss: 0.116\n",
      "[39] loss: 0.115\n",
      "[40] loss: 0.115\n",
      "[41] loss: 0.115\n",
      "[42] loss: 0.114\n",
      "[43] loss: 0.114\n",
      "[44] loss: 0.114\n",
      "[45] loss: 0.113\n",
      "[46] loss: 0.113\n",
      "[47] loss: 0.113\n",
      "[48] loss: 0.112\n",
      "[49] loss: 0.112\n",
      "[50] loss: 0.112\n",
      "[51] loss: 0.111\n",
      "[52] loss: 0.111\n",
      "[53] loss: 0.111\n",
      "[54] loss: 0.110\n",
      "[55] loss: 0.110\n",
      "[56] loss: 0.110\n",
      "[57] loss: 0.109\n",
      "[58] loss: 0.109\n",
      "[59] loss: 0.109\n",
      "[60] loss: 0.108\n",
      "[61] loss: 0.108\n",
      "[62] loss: 0.108\n",
      "[63] loss: 0.108\n",
      "[64] loss: 0.107\n",
      "[65] loss: 0.107\n",
      "[66] loss: 0.107\n",
      "[67] loss: 0.106\n",
      "[68] loss: 0.106\n",
      "[69] loss: 0.106\n",
      "[70] loss: 0.106\n",
      "[71] loss: 0.103\n",
      "[72] loss: 0.103\n",
      "[73] loss: 0.103\n",
      "[74] loss: 0.103\n",
      "[75] loss: 0.102\n",
      "[76] loss: 0.102\n",
      "[77] loss: 0.102\n",
      "[78] loss: 0.102\n",
      "[79] loss: 0.101\n",
      "[80] loss: 0.101\n",
      "[81] loss: 0.101\n",
      "[82] loss: 0.101\n",
      "[83] loss: 0.100\n",
      "[84] loss: 0.100\n",
      "[85] loss: 0.100\n",
      "[86] loss: 0.100\n",
      "[87] loss: 0.100\n",
      "[88] loss: 0.099\n",
      "[89] loss: 0.099\n",
      "[90] loss: 0.099\n",
      "[91] loss: 0.099\n",
      "[92] loss: 0.098\n",
      "[93] loss: 0.098\n",
      "[94] loss: 0.098\n",
      "[95] loss: 0.098\n",
      "[96] loss: 0.098\n",
      "[97] loss: 0.097\n",
      "[98] loss: 0.097\n",
      "[99] loss: 0.097\n",
      "[100] loss: 0.097\n",
      "[101] loss: 0.096\n",
      "[102] loss: 0.096\n",
      "[103] loss: 0.096\n",
      "[104] loss: 0.096\n",
      "[105] loss: 0.096\n",
      "[106] loss: 0.095\n",
      "[107] loss: 0.095\n",
      "[108] loss: 0.095\n",
      "[109] loss: 0.095\n",
      "[110] loss: 0.095\n",
      "[111] loss: 0.094\n",
      "[112] loss: 0.094\n",
      "[113] loss: 0.094\n",
      "[114] loss: 0.094\n",
      "[115] loss: 0.094\n",
      "[116] loss: 0.093\n",
      "[117] loss: 0.093\n",
      "[118] loss: 0.093\n",
      "[119] loss: 0.093\n",
      "[120] loss: 0.093\n",
      "[121] loss: 0.093\n",
      "[122] loss: 0.092\n",
      "[123] loss: 0.092\n",
      "[124] loss: 0.092\n",
      "[125] loss: 0.092\n",
      "[126] loss: 0.092\n",
      "[127] loss: 0.091\n",
      "[128] loss: 0.091\n",
      "[129] loss: 0.091\n",
      "[130] loss: 0.091\n",
      "[131] loss: 0.091\n",
      "[132] loss: 0.091\n",
      "[133] loss: 0.090\n",
      "[134] loss: 0.090\n",
      "[135] loss: 0.090\n",
      "[136] loss: 0.090\n",
      "[137] loss: 0.090\n",
      "[138] loss: 0.090\n",
      "[139] loss: 0.089\n",
      "[140] loss: 0.089\n",
      "[141] loss: 0.089\n",
      "[142] loss: 0.089\n",
      "[143] loss: 0.089\n",
      "[144] loss: 0.089\n",
      "[145] loss: 0.088\n",
      "[146] loss: 0.088\n",
      "[147] loss: 0.088\n",
      "[148] loss: 0.088\n",
      "[149] loss: 0.088\n",
      "[150] loss: 0.088\n",
      "[151] loss: 0.087\n",
      "[152] loss: 0.087\n",
      "[153] loss: 0.087\n",
      "[154] loss: 0.087\n",
      "[155] loss: 0.087\n",
      "[156] loss: 0.087\n",
      "[157] loss: 0.087\n",
      "[158] loss: 0.086\n",
      "[159] loss: 0.086\n",
      "[160] loss: 0.086\n",
      "[161] loss: 0.086\n",
      "[162] loss: 0.086\n",
      "[163] loss: 0.086\n",
      "[164] loss: 0.085\n",
      "[165] loss: 0.085\n",
      "[166] loss: 0.085\n",
      "[167] loss: 0.085\n",
      "[168] loss: 0.085\n",
      "[169] loss: 0.085\n",
      "[170] loss: 0.085\n",
      "[171] loss: 0.084\n",
      "[172] loss: 0.084\n",
      "[173] loss: 0.084\n",
      "[174] loss: 0.084\n",
      "[175] loss: 0.084\n",
      "[176] loss: 0.084\n",
      "[177] loss: 0.083\n",
      "[178] loss: 0.083\n",
      "[179] loss: 0.083\n",
      "[180] loss: 0.083\n",
      "[181] loss: 0.083\n",
      "[182] loss: 0.083\n",
      "[183] loss: 0.083\n",
      "[184] loss: 0.083\n",
      "[185] loss: 0.082\n",
      "[186] loss: 0.082\n",
      "[187] loss: 0.082\n",
      "[188] loss: 0.082\n",
      "[189] loss: 0.082\n",
      "[190] loss: 0.082\n",
      "[191] loss: 0.082\n",
      "[192] loss: 0.081\n",
      "[193] loss: 0.081\n",
      "[194] loss: 0.081\n",
      "[195] loss: 0.081\n",
      "[196] loss: 0.081\n",
      "[197] loss: 0.081\n",
      "[198] loss: 0.081\n",
      "[199] loss: 0.081\n",
      "[200] loss: 0.080\n",
      "[201] loss: 0.080\n",
      "[202] loss: 0.080\n",
      "[203] loss: 0.080\n",
      "[204] loss: 0.080\n",
      "[205] loss: 0.080\n",
      "[206] loss: 0.080\n",
      "[207] loss: 0.080\n",
      "[208] loss: 0.079\n",
      "[209] loss: 0.079\n",
      "[210] loss: 0.079\n",
      "[211] loss: 0.079\n",
      "[212] loss: 0.079\n",
      "[213] loss: 0.079\n",
      "[214] loss: 0.079\n",
      "[215] loss: 0.079\n",
      "[216] loss: 0.079\n",
      "[217] loss: 0.078\n",
      "[218] loss: 0.078\n",
      "[219] loss: 0.078\n",
      "[220] loss: 0.078\n",
      "[221] loss: 0.078\n",
      "[222] loss: 0.078\n",
      "[223] loss: 0.078\n",
      "[224] loss: 0.078\n",
      "[225] loss: 0.077\n",
      "[226] loss: 0.077\n",
      "[227] loss: 0.077\n",
      "[228] loss: 0.077\n",
      "[229] loss: 0.077\n",
      "[230] loss: 0.077\n",
      "[231] loss: 0.077\n",
      "[232] loss: 0.077\n",
      "[233] loss: 0.077\n",
      "[234] loss: 0.077\n",
      "[235] loss: 0.076\n",
      "[236] loss: 0.076\n",
      "[237] loss: 0.076\n",
      "[238] loss: 0.076\n",
      "[239] loss: 0.076\n",
      "[240] loss: 0.076\n",
      "[241] loss: 0.076\n",
      "[242] loss: 0.076\n",
      "[243] loss: 0.076\n",
      "[244] loss: 0.075\n",
      "[245] loss: 0.075\n",
      "[246] loss: 0.075\n",
      "[247] loss: 0.075\n",
      "[248] loss: 0.075\n",
      "[249] loss: 0.075\n",
      "[250] loss: 0.075\n",
      "[251] loss: 0.075\n",
      "[252] loss: 0.075\n",
      "[253] loss: 0.075\n",
      "[254] loss: 0.074\n",
      "[255] loss: 0.074\n",
      "[256] loss: 0.074\n",
      "[257] loss: 0.074\n",
      "[258] loss: 0.074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[259] loss: 0.074\n",
      "[260] loss: 0.074\n",
      "[261] loss: 0.074\n",
      "[262] loss: 0.074\n",
      "[263] loss: 0.074\n",
      "[264] loss: 0.074\n",
      "[265] loss: 0.073\n",
      "[266] loss: 0.073\n",
      "[267] loss: 0.073\n",
      "[268] loss: 0.073\n",
      "[269] loss: 0.073\n",
      "[270] loss: 0.073\n",
      "[271] loss: 0.073\n",
      "[272] loss: 0.073\n",
      "[273] loss: 0.073\n",
      "[274] loss: 0.073\n",
      "[275] loss: 0.073\n",
      "[276] loss: 0.072\n",
      "[277] loss: 0.072\n",
      "[278] loss: 0.072\n",
      "[279] loss: 0.072\n",
      "[280] loss: 0.072\n",
      "[281] loss: 0.072\n",
      "[282] loss: 0.072\n",
      "[283] loss: 0.072\n",
      "[284] loss: 0.072\n",
      "[285] loss: 0.072\n",
      "[286] loss: 0.072\n",
      "[287] loss: 0.072\n",
      "[288] loss: 0.071\n",
      "[289] loss: 0.071\n",
      "[290] loss: 0.071\n",
      "[291] loss: 0.071\n",
      "[292] loss: 0.071\n",
      "[293] loss: 0.071\n",
      "[294] loss: 0.071\n",
      "[295] loss: 0.071\n",
      "[296] loss: 0.071\n",
      "[297] loss: 0.071\n",
      "[298] loss: 0.071\n",
      "[299] loss: 0.071\n",
      "[300] loss: 0.071\n",
      "[301] loss: 0.070\n",
      "[302] loss: 0.070\n",
      "[303] loss: 0.070\n",
      "[304] loss: 0.070\n",
      "[305] loss: 0.070\n",
      "[306] loss: 0.070\n",
      "[307] loss: 0.070\n",
      "[308] loss: 0.070\n",
      "[309] loss: 0.070\n",
      "[310] loss: 0.070\n",
      "[311] loss: 0.070\n",
      "[312] loss: 0.070\n",
      "[313] loss: 0.070\n",
      "[314] loss: 0.070\n",
      "[315] loss: 0.069\n",
      "[316] loss: 0.069\n",
      "[317] loss: 0.069\n",
      "[318] loss: 0.069\n",
      "[319] loss: 0.069\n",
      "[320] loss: 0.069\n",
      "[321] loss: 0.069\n",
      "[322] loss: 0.069\n",
      "[323] loss: 0.069\n",
      "[324] loss: 0.069\n",
      "[325] loss: 0.069\n",
      "[326] loss: 0.069\n",
      "[327] loss: 0.069\n",
      "[328] loss: 0.069\n",
      "[329] loss: 0.069\n",
      "[330] loss: 0.069\n",
      "[331] loss: 0.068\n",
      "[332] loss: 0.068\n",
      "[333] loss: 0.068\n",
      "[334] loss: 0.068\n",
      "[335] loss: 0.068\n",
      "[336] loss: 0.068\n",
      "[337] loss: 0.068\n",
      "[338] loss: 0.068\n",
      "[339] loss: 0.068\n",
      "[340] loss: 0.068\n",
      "[341] loss: 0.068\n",
      "[342] loss: 0.068\n",
      "[343] loss: 0.067\n",
      "[344] loss: 0.067\n",
      "[345] loss: 0.066\n",
      "[346] loss: 0.066\n",
      "[347] loss: 0.066\n",
      "[348] loss: 0.066\n",
      "[349] loss: 0.066\n",
      "[350] loss: 0.066\n",
      "[351] loss: 0.066\n",
      "[352] loss: 0.066\n",
      "[353] loss: 0.066\n",
      "[354] loss: 0.066\n",
      "[355] loss: 0.066\n",
      "[356] loss: 0.066\n",
      "[357] loss: 0.066\n",
      "[358] loss: 0.066\n",
      "[359] loss: 0.066\n",
      "[360] loss: 0.066\n",
      "[361] loss: 0.066\n",
      "[362] loss: 0.066\n",
      "[363] loss: 0.066\n",
      "[364] loss: 0.066\n",
      "[365] loss: 0.066\n",
      "[366] loss: 0.066\n",
      "[367] loss: 0.065\n",
      "[368] loss: 0.065\n",
      "[369] loss: 0.065\n",
      "[370] loss: 0.065\n",
      "[371] loss: 0.065\n",
      "[372] loss: 0.065\n",
      "[373] loss: 0.065\n",
      "[374] loss: 0.065\n",
      "[375] loss: 0.065\n",
      "[376] loss: 0.065\n",
      "[377] loss: 0.065\n",
      "[378] loss: 0.065\n",
      "[379] loss: 0.065\n",
      "[380] loss: 0.065\n",
      "[381] loss: 0.065\n",
      "[382] loss: 0.065\n",
      "[383] loss: 0.065\n",
      "[384] loss: 0.065\n",
      "[385] loss: 0.065\n",
      "[386] loss: 0.065\n",
      "[387] loss: 0.065\n",
      "[388] loss: 0.065\n",
      "[389] loss: 0.065\n",
      "[390] loss: 0.065\n",
      "[391] loss: 0.065\n",
      "[392] loss: 0.065\n",
      "[393] loss: 0.064\n",
      "[394] loss: 0.064\n",
      "[395] loss: 0.064\n",
      "[396] loss: 0.064\n",
      "[397] loss: 0.064\n",
      "[398] loss: 0.064\n",
      "[399] loss: 0.064\n",
      "[400] loss: 0.064\n",
      "[401] loss: 0.064\n",
      "[402] loss: 0.064\n",
      "[403] loss: 0.064\n",
      "[404] loss: 0.064\n",
      "[405] loss: 0.064\n",
      "[406] loss: 0.064\n",
      "[407] loss: 0.064\n",
      "[408] loss: 0.064\n",
      "[409] loss: 0.064\n",
      "[410] loss: 0.064\n",
      "[411] loss: 0.064\n",
      "[412] loss: 0.064\n",
      "[413] loss: 0.064\n",
      "[414] loss: 0.064\n",
      "[415] loss: 0.064\n",
      "[416] loss: 0.064\n",
      "[417] loss: 0.064\n",
      "[418] loss: 0.064\n",
      "[419] loss: 0.064\n",
      "[420] loss: 0.064\n",
      "[421] loss: 0.064\n",
      "[422] loss: 0.064\n",
      "[423] loss: 0.064\n",
      "[424] loss: 0.064\n",
      "[425] loss: 0.064\n",
      "[426] loss: 0.063\n",
      "[427] loss: 0.063\n",
      "[428] loss: 0.063\n",
      "[429] loss: 0.063\n",
      "[430] loss: 0.063\n",
      "[431] loss: 0.063\n",
      "[432] loss: 0.063\n",
      "[433] loss: 0.063\n",
      "[434] loss: 0.063\n",
      "[435] loss: 0.063\n",
      "[436] loss: 0.063\n",
      "[437] loss: 0.063\n",
      "[438] loss: 0.063\n",
      "[439] loss: 0.063\n",
      "[440] loss: 0.063\n",
      "[441] loss: 0.063\n",
      "[442] loss: 0.063\n",
      "[443] loss: 0.063\n",
      "[444] loss: 0.063\n",
      "[445] loss: 0.063\n",
      "[446] loss: 0.063\n",
      "[447] loss: 0.063\n",
      "[448] loss: 0.063\n",
      "[449] loss: 0.063\n",
      "[450] loss: 0.063\n",
      "[451] loss: 0.063\n",
      "[452] loss: 0.063\n",
      "[453] loss: 0.063\n",
      "[454] loss: 0.063\n",
      "[455] loss: 0.063\n",
      "[456] loss: 0.063\n",
      "[457] loss: 0.063\n",
      "[458] loss: 0.063\n",
      "[459] loss: 0.063\n",
      "[460] loss: 0.063\n",
      "[461] loss: 0.063\n",
      "[462] loss: 0.063\n",
      "[463] loss: 0.063\n",
      "[464] loss: 0.063\n",
      "[465] loss: 0.063\n",
      "[466] loss: 0.063\n",
      "[467] loss: 0.062\n",
      "[468] loss: 0.062\n",
      "[469] loss: 0.062\n",
      "[470] loss: 0.062\n",
      "[471] loss: 0.062\n",
      "[472] loss: 0.062\n",
      "[473] loss: 0.062\n",
      "[474] loss: 0.062\n",
      "[475] loss: 0.062\n",
      "[476] loss: 0.062\n",
      "[477] loss: 0.062\n",
      "[478] loss: 0.062\n",
      "[479] loss: 0.062\n",
      "[480] loss: 0.062\n",
      "[481] loss: 0.062\n",
      "[482] loss: 0.062\n",
      "[483] loss: 0.062\n",
      "[484] loss: 0.062\n",
      "[485] loss: 0.062\n",
      "[486] loss: 0.062\n",
      "[487] loss: 0.062\n",
      "[488] loss: 0.062\n",
      "[489] loss: 0.062\n",
      "[490] loss: 0.062\n",
      "[491] loss: 0.062\n",
      "[492] loss: 0.062\n",
      "[493] loss: 0.062\n",
      "[494] loss: 0.062\n",
      "[495] loss: 0.062\n",
      "[496] loss: 0.062\n",
      "[497] loss: 0.062\n",
      "[498] loss: 0.061\n",
      "[499] loss: 0.061\n",
      "[500] loss: 0.061\n",
      "[501] loss: 0.061\n",
      "[502] loss: 0.061\n",
      "[503] loss: 0.061\n",
      "[504] loss: 0.061\n",
      "[505] loss: 0.061\n",
      "[506] loss: 0.061\n",
      "[507] loss: 0.061\n",
      "[508] loss: 0.061\n",
      "[509] loss: 0.061\n",
      "[510] loss: 0.061\n",
      "[511] loss: 0.061\n",
      "[512] loss: 0.061\n",
      "[513] loss: 0.061\n",
      "[514] loss: 0.061\n",
      "[515] loss: 0.061\n",
      "[516] loss: 0.061\n",
      "[517] loss: 0.061\n",
      "[518] loss: 0.061\n",
      "[519] loss: 0.061\n",
      "[520] loss: 0.061\n",
      "[521] loss: 0.061\n",
      "[522] loss: 0.061\n",
      "[523] loss: 0.061\n",
      "[524] loss: 0.061\n",
      "[525] loss: 0.061\n",
      "[526] loss: 0.061\n",
      "[527] loss: 0.061\n",
      "[528] loss: 0.061\n",
      "[529] loss: 0.061\n",
      "[530] loss: 0.061\n",
      "[531] loss: 0.061\n",
      "[532] loss: 0.061\n",
      "[533] loss: 0.061\n",
      "[534] loss: 0.061\n",
      "[535] loss: 0.061\n",
      "[536] loss: 0.061\n",
      "[537] loss: 0.061\n",
      "[538] loss: 0.061\n",
      "[539] loss: 0.061\n",
      "[540] loss: 0.061\n",
      "[541] loss: 0.061\n",
      "[542] loss: 0.061\n",
      "[543] loss: 0.061\n",
      "[544] loss: 0.061\n",
      "[545] loss: 0.061\n",
      "[546] loss: 0.061\n",
      "[547] loss: 0.061\n",
      "[548] loss: 0.061\n",
      "[549] loss: 0.061\n",
      "[550] loss: 0.061\n",
      "[551] loss: 0.061\n",
      "[552] loss: 0.061\n",
      "[553] loss: 0.061\n",
      "[554] loss: 0.061\n",
      "[555] loss: 0.061\n",
      "[556] loss: 0.061\n",
      "[557] loss: 0.061\n",
      "[558] loss: 0.061\n",
      "[559] loss: 0.061\n",
      "[560] loss: 0.061\n",
      "[561] loss: 0.061\n",
      "[562] loss: 0.061\n",
      "[563] loss: 0.061\n",
      "[564] loss: 0.061\n",
      "[565] loss: 0.061\n",
      "[566] loss: 0.061\n",
      "[567] loss: 0.061\n",
      "[568] loss: 0.061\n",
      "[569] loss: 0.061\n",
      "[570] loss: 0.060\n",
      "[571] loss: 0.060\n",
      "[572] loss: 0.060\n",
      "[573] loss: 0.060\n",
      "[574] loss: 0.060\n",
      "[575] loss: 0.060\n",
      "[576] loss: 0.060\n",
      "[577] loss: 0.060\n",
      "[578] loss: 0.060\n",
      "[579] loss: 0.060\n",
      "[580] loss: 0.060\n",
      "[581] loss: 0.060\n",
      "[582] loss: 0.060\n",
      "[583] loss: 0.060\n",
      "[584] loss: 0.060\n",
      "[585] loss: 0.060\n",
      "[586] loss: 0.060\n",
      "[587] loss: 0.060\n",
      "[588] loss: 0.060\n",
      "[589] loss: 0.060\n",
      "[590] loss: 0.060\n",
      "[591] loss: 0.060\n",
      "[592] loss: 0.060\n",
      "[593] loss: 0.060\n",
      "[594] loss: 0.060\n",
      "[595] loss: 0.060\n",
      "[596] loss: 0.060\n",
      "[597] loss: 0.060\n",
      "[598] loss: 0.060\n",
      "[599] loss: 0.060\n",
      "[600] loss: 0.060\n",
      "[601] loss: 0.060\n",
      "[602] loss: 0.060\n",
      "[603] loss: 0.060\n",
      "[604] loss: 0.060\n",
      "[605] loss: 0.060\n",
      "[606] loss: 0.060\n",
      "[607] loss: 0.060\n",
      "[608] loss: 0.060\n",
      "[609] loss: 0.060\n",
      "[610] loss: 0.060\n",
      "[611] loss: 0.060\n",
      "[612] loss: 0.060\n",
      "[613] loss: 0.060\n",
      "[614] loss: 0.060\n",
      "[615] loss: 0.060\n",
      "[616] loss: 0.060\n",
      "[617] loss: 0.060\n",
      "[618] loss: 0.060\n",
      "[619] loss: 0.060\n",
      "[620] loss: 0.060\n",
      "[621] loss: 0.060\n",
      "[622] loss: 0.060\n",
      "[623] loss: 0.060\n",
      "[624] loss: 0.060\n",
      "[625] loss: 0.060\n",
      "[626] loss: 0.060\n",
      "[627] loss: 0.060\n",
      "[628] loss: 0.060\n",
      "[629] loss: 0.060\n",
      "[630] loss: 0.060\n",
      "[631] loss: 0.059\n",
      "[632] loss: 0.059\n",
      "[633] loss: 0.059\n",
      "[634] loss: 0.059\n",
      "[635] loss: 0.059\n",
      "[636] loss: 0.059\n",
      "[637] loss: 0.059\n",
      "[638] loss: 0.059\n",
      "[639] loss: 0.059\n",
      "[640] loss: 0.059\n",
      "[641] loss: 0.059\n",
      "[642] loss: 0.059\n",
      "[643] loss: 0.059\n",
      "[644] loss: 0.059\n",
      "[645] loss: 0.059\n",
      "[646] loss: 0.059\n",
      "[647] loss: 0.059\n",
      "[648] loss: 0.059\n",
      "[649] loss: 0.059\n",
      "[650] loss: 0.059\n",
      "[651] loss: 0.059\n",
      "[652] loss: 0.059\n",
      "[653] loss: 0.059\n",
      "[654] loss: 0.059\n",
      "[655] loss: 0.059\n",
      "[656] loss: 0.059\n",
      "[657] loss: 0.059\n",
      "[658] loss: 0.059\n",
      "[659] loss: 0.059\n",
      "[660] loss: 0.059\n",
      "[661] loss: 0.059\n",
      "[662] loss: 0.059\n",
      "[663] loss: 0.059\n",
      "[664] loss: 0.059\n",
      "[665] loss: 0.059\n",
      "[666] loss: 0.059\n",
      "[667] loss: 0.059\n",
      "[668] loss: 0.059\n",
      "[669] loss: 0.059\n",
      "[670] loss: 0.059\n",
      "[671] loss: 0.059\n",
      "[672] loss: 0.059\n",
      "[673] loss: 0.059\n",
      "[674] loss: 0.059\n",
      "[675] loss: 0.059\n",
      "[676] loss: 0.059\n",
      "[677] loss: 0.059\n",
      "[678] loss: 0.059\n",
      "[679] loss: 0.059\n",
      "[680] loss: 0.059\n",
      "[681] loss: 0.059\n",
      "[682] loss: 0.059\n",
      "[683] loss: 0.059\n",
      "[684] loss: 0.059\n",
      "[685] loss: 0.059\n",
      "[686] loss: 0.059\n",
      "[687] loss: 0.059\n",
      "[688] loss: 0.059\n",
      "[689] loss: 0.059\n",
      "[690] loss: 0.059\n",
      "[691] loss: 0.059\n",
      "[692] loss: 0.059\n",
      "[693] loss: 0.059\n",
      "[694] loss: 0.059\n",
      "[695] loss: 0.059\n",
      "[696] loss: 0.059\n",
      "[697] loss: 0.059\n",
      "[698] loss: 0.059\n",
      "[699] loss: 0.059\n",
      "[700] loss: 0.059\n",
      "[701] loss: 0.059\n",
      "[702] loss: 0.059\n",
      "[703] loss: 0.059\n",
      "[704] loss: 0.059\n",
      "[705] loss: 0.059\n",
      "[706] loss: 0.059\n",
      "[707] loss: 0.059\n",
      "[708] loss: 0.059\n",
      "[709] loss: 0.059\n",
      "[710] loss: 0.059\n",
      "[711] loss: 0.059\n",
      "[712] loss: 0.059\n",
      "[713] loss: 0.059\n",
      "[714] loss: 0.059\n",
      "[715] loss: 0.059\n",
      "[716] loss: 0.059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[717] loss: 0.059\n",
      "[718] loss: 0.059\n",
      "[719] loss: 0.059\n",
      "[720] loss: 0.059\n",
      "[721] loss: 0.059\n",
      "[722] loss: 0.059\n",
      "[723] loss: 0.059\n",
      "[724] loss: 0.059\n",
      "[725] loss: 0.059\n",
      "[726] loss: 0.059\n",
      "[727] loss: 0.058\n",
      "[728] loss: 0.058\n",
      "[729] loss: 0.058\n",
      "[730] loss: 0.058\n",
      "[731] loss: 0.058\n",
      "[732] loss: 0.058\n",
      "[733] loss: 0.058\n",
      "[734] loss: 0.058\n",
      "[735] loss: 0.058\n",
      "[736] loss: 0.058\n",
      "[737] loss: 0.058\n",
      "[738] loss: 0.058\n",
      "[739] loss: 0.058\n",
      "[740] loss: 0.058\n",
      "[741] loss: 0.058\n",
      "[742] loss: 0.058\n",
      "[743] loss: 0.058\n",
      "[744] loss: 0.058\n",
      "[745] loss: 0.058\n",
      "[746] loss: 0.058\n",
      "[747] loss: 0.058\n",
      "[748] loss: 0.058\n",
      "[749] loss: 0.058\n",
      "[750] loss: 0.058\n",
      "[751] loss: 0.058\n",
      "[752] loss: 0.058\n",
      "[753] loss: 0.058\n",
      "[754] loss: 0.058\n",
      "[755] loss: 0.058\n",
      "[756] loss: 0.058\n",
      "[757] loss: 0.058\n",
      "[758] loss: 0.058\n",
      "[759] loss: 0.058\n",
      "[760] loss: 0.058\n",
      "[761] loss: 0.058\n",
      "[762] loss: 0.058\n",
      "[763] loss: 0.058\n",
      "[764] loss: 0.058\n",
      "[765] loss: 0.058\n",
      "[766] loss: 0.058\n",
      "[767] loss: 0.058\n",
      "[768] loss: 0.058\n",
      "[769] loss: 0.058\n",
      "[770] loss: 0.058\n",
      "[771] loss: 0.058\n",
      "[772] loss: 0.058\n",
      "[773] loss: 0.058\n",
      "[774] loss: 0.058\n",
      "[775] loss: 0.058\n",
      "[776] loss: 0.058\n",
      "[777] loss: 0.058\n",
      "[778] loss: 0.058\n",
      "[779] loss: 0.058\n",
      "[780] loss: 0.058\n",
      "[781] loss: 0.058\n",
      "[782] loss: 0.058\n",
      "[783] loss: 0.058\n",
      "[784] loss: 0.058\n",
      "[785] loss: 0.058\n",
      "[786] loss: 0.058\n",
      "[787] loss: 0.058\n",
      "[788] loss: 0.058\n",
      "[789] loss: 0.058\n",
      "[790] loss: 0.058\n",
      "[791] loss: 0.058\n",
      "[792] loss: 0.058\n",
      "[793] loss: 0.058\n",
      "[794] loss: 0.058\n",
      "[795] loss: 0.058\n",
      "[796] loss: 0.058\n",
      "[797] loss: 0.058\n",
      "[798] loss: 0.058\n",
      "[799] loss: 0.058\n",
      "[800] loss: 0.058\n",
      "[801] loss: 0.058\n",
      "[802] loss: 0.058\n",
      "[803] loss: 0.058\n",
      "[804] loss: 0.058\n",
      "[805] loss: 0.058\n",
      "[806] loss: 0.058\n",
      "[807] loss: 0.058\n",
      "[808] loss: 0.058\n",
      "[809] loss: 0.058\n",
      "[810] loss: 0.058\n",
      "[811] loss: 0.058\n",
      "[812] loss: 0.058\n",
      "[813] loss: 0.058\n",
      "[814] loss: 0.058\n",
      "[815] loss: 0.058\n",
      "[816] loss: 0.058\n",
      "[817] loss: 0.058\n",
      "[818] loss: 0.058\n",
      "[819] loss: 0.058\n",
      "[820] loss: 0.058\n",
      "[821] loss: 0.058\n",
      "[822] loss: 0.058\n",
      "[823] loss: 0.058\n",
      "[824] loss: 0.058\n",
      "[825] loss: 0.058\n",
      "[826] loss: 0.058\n",
      "[827] loss: 0.058\n",
      "[828] loss: 0.058\n",
      "[829] loss: 0.058\n",
      "[830] loss: 0.058\n",
      "[831] loss: 0.058\n",
      "[832] loss: 0.058\n",
      "[833] loss: 0.058\n",
      "[834] loss: 0.058\n",
      "[835] loss: 0.058\n",
      "[836] loss: 0.058\n",
      "[837] loss: 0.058\n",
      "[838] loss: 0.058\n",
      "[839] loss: 0.058\n",
      "[840] loss: 0.058\n",
      "[841] loss: 0.058\n",
      "[842] loss: 0.058\n",
      "[843] loss: 0.058\n",
      "[844] loss: 0.058\n",
      "[845] loss: 0.058\n",
      "[846] loss: 0.058\n",
      "[847] loss: 0.058\n",
      "[848] loss: 0.058\n",
      "[849] loss: 0.058\n",
      "[850] loss: 0.058\n",
      "[851] loss: 0.058\n",
      "[852] loss: 0.058\n",
      "[853] loss: 0.058\n",
      "[854] loss: 0.058\n",
      "[855] loss: 0.058\n",
      "[856] loss: 0.057\n",
      "[857] loss: 0.057\n",
      "[858] loss: 0.057\n",
      "[859] loss: 0.057\n",
      "[860] loss: 0.057\n",
      "[861] loss: 0.057\n",
      "[862] loss: 0.057\n",
      "[863] loss: 0.057\n",
      "[864] loss: 0.057\n",
      "[865] loss: 0.057\n",
      "[866] loss: 0.057\n",
      "[867] loss: 0.057\n",
      "[868] loss: 0.057\n",
      "[869] loss: 0.057\n",
      "[870] loss: 0.057\n",
      "[871] loss: 0.057\n",
      "[872] loss: 0.057\n",
      "[873] loss: 0.057\n",
      "[874] loss: 0.057\n",
      "[875] loss: 0.057\n",
      "[876] loss: 0.057\n",
      "[877] loss: 0.057\n",
      "[878] loss: 0.057\n",
      "[879] loss: 0.057\n",
      "[880] loss: 0.057\n",
      "[881] loss: 0.057\n",
      "[882] loss: 0.057\n",
      "[883] loss: 0.057\n",
      "[884] loss: 0.057\n",
      "[885] loss: 0.057\n",
      "[886] loss: 0.057\n",
      "[887] loss: 0.057\n",
      "[888] loss: 0.057\n",
      "[889] loss: 0.057\n",
      "[890] loss: 0.057\n",
      "[891] loss: 0.057\n",
      "[892] loss: 0.057\n",
      "[893] loss: 0.057\n",
      "[894] loss: 0.057\n",
      "[895] loss: 0.057\n",
      "[896] loss: 0.057\n",
      "[897] loss: 0.057\n",
      "[898] loss: 0.057\n",
      "[899] loss: 0.057\n",
      "[900] loss: 0.057\n",
      "[901] loss: 0.057\n",
      "[902] loss: 0.057\n",
      "[903] loss: 0.057\n",
      "[904] loss: 0.057\n",
      "[905] loss: 0.057\n",
      "[906] loss: 0.057\n",
      "[907] loss: 0.057\n",
      "[908] loss: 0.057\n",
      "[909] loss: 0.057\n",
      "[910] loss: 0.057\n",
      "[911] loss: 0.057\n",
      "[912] loss: 0.057\n",
      "[913] loss: 0.057\n",
      "[914] loss: 0.057\n",
      "[915] loss: 0.057\n",
      "[916] loss: 0.057\n",
      "[917] loss: 0.057\n",
      "[918] loss: 0.057\n",
      "[919] loss: 0.057\n",
      "[920] loss: 0.057\n",
      "[921] loss: 0.057\n",
      "[922] loss: 0.057\n",
      "[923] loss: 0.057\n",
      "[924] loss: 0.057\n",
      "[925] loss: 0.057\n",
      "[926] loss: 0.057\n",
      "[927] loss: 0.057\n",
      "[928] loss: 0.057\n",
      "[929] loss: 0.057\n",
      "[930] loss: 0.057\n",
      "[931] loss: 0.057\n",
      "[932] loss: 0.057\n",
      "[933] loss: 0.057\n",
      "[934] loss: 0.057\n",
      "[935] loss: 0.057\n",
      "[936] loss: 0.057\n",
      "[937] loss: 0.057\n",
      "[938] loss: 0.057\n",
      "[939] loss: 0.057\n",
      "[940] loss: 0.057\n",
      "[941] loss: 0.057\n",
      "[942] loss: 0.057\n",
      "[943] loss: 0.057\n",
      "[944] loss: 0.057\n",
      "[945] loss: 0.057\n",
      "[946] loss: 0.057\n",
      "[947] loss: 0.057\n",
      "[948] loss: 0.057\n",
      "[949] loss: 0.057\n",
      "[950] loss: 0.057\n",
      "[951] loss: 0.057\n",
      "[952] loss: 0.057\n",
      "[953] loss: 0.057\n",
      "[954] loss: 0.057\n",
      "[955] loss: 0.057\n",
      "[956] loss: 0.057\n",
      "[957] loss: 0.057\n",
      "[958] loss: 0.057\n",
      "[959] loss: 0.057\n",
      "[960] loss: 0.057\n",
      "[961] loss: 0.057\n",
      "[962] loss: 0.057\n",
      "[963] loss: 0.057\n",
      "[964] loss: 0.057\n",
      "[965] loss: 0.057\n",
      "[966] loss: 0.057\n",
      "[967] loss: 0.057\n",
      "[968] loss: 0.057\n",
      "[969] loss: 0.057\n",
      "[970] loss: 0.057\n",
      "[971] loss: 0.057\n",
      "[972] loss: 0.057\n",
      "[973] loss: 0.057\n",
      "[974] loss: 0.057\n",
      "[975] loss: 0.057\n",
      "[976] loss: 0.057\n",
      "[977] loss: 0.057\n",
      "[978] loss: 0.057\n",
      "[979] loss: 0.057\n",
      "[980] loss: 0.057\n",
      "[981] loss: 0.057\n",
      "[982] loss: 0.057\n",
      "[983] loss: 0.057\n",
      "[984] loss: 0.057\n",
      "[985] loss: 0.057\n",
      "[986] loss: 0.057\n",
      "[987] loss: 0.057\n",
      "[988] loss: 0.057\n",
      "[989] loss: 0.057\n",
      "[990] loss: 0.057\n",
      "[991] loss: 0.057\n",
      "[992] loss: 0.057\n",
      "[993] loss: 0.057\n",
      "[994] loss: 0.057\n",
      "[995] loss: 0.057\n",
      "[996] loss: 0.056\n",
      "[997] loss: 0.056\n",
      "[998] loss: 0.056\n",
      "[999] loss: 0.056\n",
      "[1000] loss: 0.056\n",
      "print trained parameters:\n",
      "Parameter containing:\n",
      " 0.0000 -0.3116  0.4476 -0.1411  0.0000\n",
      "-0.3503  0.3641 -0.4267 -0.2111  0.0000\n",
      "-0.3453 -0.1940 -0.4201  0.0000 -0.4149\n",
      "-0.1100  0.4635  0.2788  0.3271  0.2949\n",
      "-0.4770 -0.3487 -0.3141 -0.2742  0.0000\n",
      " 0.4323 -0.1152  0.3731  0.3104  0.0000\n",
      "-0.2794 -0.4027  0.1108  0.3793 -0.2245\n",
      "-0.3891  0.4377 -0.1120  0.4030 -0.2948\n",
      "-0.2102 -0.4017 -0.1128 -0.3762 -0.2422\n",
      "-0.4774  0.2289  0.3663  0.1248  0.0000\n",
      "[torch.FloatTensor of size 10x5]\n",
      "\n",
      "Parameter containing:\n",
      "-0.3408\n",
      "-0.3457\n",
      " 0.0000\n",
      "-0.1539\n",
      " 0.1702\n",
      " 0.2217\n",
      " 0.3571\n",
      " 0.1840\n",
      "-0.3840\n",
      "-0.1308\n",
      "[torch.FloatTensor of size 10]\n",
      "\n",
      "Parameter containing:\n",
      "-0.2007  0.0000  0.0000  0.0000 -0.1708 -0.1730  0.1661  0.0000  0.2165  0.0000\n",
      " 0.0000  0.0000  0.2465  0.1026  0.2441  0.1531  0.0000  0.0000  0.1554 -0.1630\n",
      " 0.0000  0.3280 -0.1545 -0.2521  0.2147  0.0000 -0.1909  0.0000  0.3738  0.3364\n",
      "[torch.FloatTensor of size 3x10]\n",
      "\n",
      "Parameter containing:\n",
      " 0.0000\n",
      " 0.1762\n",
      "-0.2439\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Parameter containing:\n",
      " 0.2374  0.0000 -0.4595\n",
      " 0.3069 -0.3144  0.0000\n",
      "-0.3573  0.4443  0.1932\n",
      " 0.0000  0.2296  0.0000\n",
      " 0.0000  0.2102  0.5510\n",
      " 0.2390  0.2292  0.3719\n",
      "-0.4440  0.2944 -0.3153\n",
      " 0.3221  0.0000 -0.4727\n",
      " 0.3208  0.4073  0.4286\n",
      "-0.3333 -0.3691 -0.4640\n",
      "[torch.FloatTensor of size 10x3]\n",
      "\n",
      "Parameter containing:\n",
      "-0.4863\n",
      "-0.5219\n",
      " 0.0000\n",
      "-0.2523\n",
      "-0.1735\n",
      " 0.0000\n",
      " 0.2911\n",
      "-0.4087\n",
      " 0.2007\n",
      "-0.1728\n",
      "[torch.FloatTensor of size 10]\n",
      "\n",
      "Parameter containing:\n",
      " 0.2644  0.0000  0.0000  0.0000 -0.3909  0.0000 -0.1127  0.2404  0.0000  0.0000\n",
      " 0.2321 -0.3128  0.0000 -0.1855 -0.1868  0.0000  0.0000  0.1790  0.1186  0.0000\n",
      " 0.0000  0.0000 -0.3969  0.0000  0.0000  0.0000  0.0000 -0.2903  0.0000  0.0000\n",
      "-0.2422 -0.3004  0.0000 -0.3185  0.0000  0.0000  0.3679  0.1607  0.0000  0.0000\n",
      " 0.0000  0.1787  0.0000  0.2113 -0.3348  0.0000 -0.1056  0.0000 -0.3131  0.2079\n",
      "[torch.FloatTensor of size 5x10]\n",
      "\n",
      "Parameter containing:\n",
      " 0.2990\n",
      " 0.2023\n",
      " 0.4378\n",
      " 0.0000\n",
      " 0.2862\n",
      "[torch.FloatTensor of size 5]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "loss0   = 0\n",
    "epsilon = 0.00001\n",
    "print('print initial parameters:')\n",
    "for i in net.parameters():\n",
    "    print(i)\n",
    "    \n",
    "for epoch in range(100):\n",
    "    \n",
    "    optimizer.zero_grad()   # zero the gradient buffers\n",
    "    out  = net.forward(data)\n",
    "    loss = criterion(out,data)\n",
    "    print('[%d] loss: %.3f' %\n",
    "                  (epoch + 1, loss.data[0]))\n",
    "    if abs(loss.data[0]-loss0) < epsilon:\n",
    "        break\n",
    "    loss0 = loss.data[0]\n",
    "    loss.backward()\n",
    "    optimizer.step()        # Does the update\n",
    "    \n",
    "for epoch in range(1000):\n",
    "    \n",
    "    optimizer.zero_grad()   # zero the gradient buffers\n",
    "    out  = net.forward(data)\n",
    "    loss = criterion(out,data)\n",
    "    print('[%d] loss: %.3f' %\n",
    "                  (epoch + 1, loss.data[0]))\n",
    "    #if abs(loss.data[0]-loss0) < epsilon:\n",
    "        #break\n",
    "    loss0 = loss.data[0]\n",
    "    loss.backward()\n",
    "    optimizer.step()        # Does the update\n",
    "    for i in net.parameters():\n",
    "        para = i.data\n",
    "        mask = (torch.abs(para)<0.1)\n",
    "        mask = mask.type(torch.FloatTensor)\n",
    "        i.data.addcmul_(-1.0,i.data,mask)\n",
    "\n",
    "        \n",
    "print('print trained parameters:')\n",
    "for i in net.parameters():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Analysis\n",
    "To show the relation ship between each col of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.00000000e+00   7.07733549e-01   5.27606298e-04   2.87293145e-03\n",
      "    3.53224538e-03]\n",
      " [  7.07733549e-01   1.00000000e+00   7.06852764e-01   5.01114907e-01\n",
      "    2.17728536e-03]\n",
      " [  5.27606298e-04   7.06852764e-01   1.00000000e+00   7.06436164e-01\n",
      "   -4.54771235e-04]\n",
      " [  2.87293145e-03   5.01114907e-01   7.06436164e-01   1.00000000e+00\n",
      "    7.07455423e-01]\n",
      " [  3.53224538e-03   2.17728536e-03  -4.54771235e-04   7.07455423e-01\n",
      "    1.00000000e+00]]\n",
      "[[ 0.          0.          0.86749462  0.36361875  0.26400134]\n",
      " [ 0.          0.          0.          0.          0.49113149]\n",
      " [ 0.86749462  0.          0.          0.          0.8856509 ]\n",
      " [ 0.36361875  0.          0.          0.          0.        ]\n",
      " [ 0.26400134  0.49113149  0.8856509   0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "r = np.zeros([5,5])\n",
    "p = np.zeros([5,5])\n",
    "\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        r[i,j],p[i,j] = stats.pearsonr(np_data[:,i],np_data[:,j])\n",
    "print(r)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBSCAN\n",
    "Density-based spatial clustering of applications with noise is a cluster algorithm proposed by Martin Ester .etc. It is able to find cluster in any shape and does not need to specify the number of clusters in advance.\n",
    "\n",
    "We require that for every point p in a cluster C there is a point q in C so that p is inside of the Eps-\n",
    "neighborhood of q and NEps(q) contains at least MinPts points.\n",
    "\n",
    "We use the scikit-learn tool kits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "Estimated number of clusters: 3\n",
      "Homogeneity: 0.953\n",
      "Completeness: 0.883\n",
      "V-measure: 0.917\n",
      "Adjusted Rand Index: 0.952\n",
      "Adjusted Mutual Information: 0.883\n",
      "Silhouette Coefficient: 0.626\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEICAYAAABWJCMKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9854626c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# #############################################################################\n",
    "# Generate sample data\n",
    "centers = [[1, 1], [-1, -1], [1, -1]]\n",
    "X, labels_true = make_blobs(n_samples=750, centers=centers, cluster_std=0.4,\n",
    "                            random_state=0)\n",
    "\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "# #############################################################################\n",
    "# Compute DBSCAN\n",
    "db = DBSCAN(eps=0.3, min_samples=10).fit(X)\n",
    "core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "core_samples_mask[db.core_sample_indices_] = True\n",
    "labels = db.labels_\n",
    "\n",
    "# Number of clusters in labels, ignoring noise if present.\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "\n",
    "print('Estimated number of clusters: %d' % n_clusters_)\n",
    "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels_true, labels))\n",
    "print(\"Completeness: %0.3f\" % metrics.completeness_score(labels_true, labels))\n",
    "print(\"V-measure: %0.3f\" % metrics.v_measure_score(labels_true, labels))\n",
    "print(\"Adjusted Rand Index: %0.3f\"\n",
    "      % metrics.adjusted_rand_score(labels_true, labels))\n",
    "print(\"Adjusted Mutual Information: %0.3f\"\n",
    "      % metrics.adjusted_mutual_info_score(labels_true, labels))\n",
    "print(\"Silhouette Coefficient: %0.3f\"\n",
    "      % metrics.silhouette_score(X, labels))\n",
    "\n",
    "# #############################################################################\n",
    "# Plot result\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Black removed and is used for noise instead.\n",
    "unique_labels = set(labels)\n",
    "colors = [plt.cm.Spectral(each)\n",
    "          for each in np.linspace(0, 1, len(unique_labels))]\n",
    "for k, col in zip(unique_labels, colors):\n",
    "    if k == -1:\n",
    "        # Black used for noise.\n",
    "        col = [0, 0, 0, 1]\n",
    "\n",
    "    class_member_mask = (labels == k)\n",
    "\n",
    "    xy = X[class_member_mask & core_samples_mask]\n",
    "    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n",
    "             markeredgecolor='k', markersize=14)\n",
    "\n",
    "    xy = X[class_member_mask & ~core_samples_mask]\n",
    "    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n",
    "             markeredgecolor='k', markersize=6)\n",
    "\n",
    "plt.title('Estimated number of clusters: %d' % n_clusters_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TAN classifier\n",
    "TAN classifier is the Tree Augmented Naive Baysian, which is created by adding a spaned tree into naive baysian network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from collections import defaultdict\n",
    "\n",
    "class node:\n",
    "    '''\n",
    "    The class to store the information of a node in a graph\n",
    "    '''\n",
    "    def __init__(self,name,domain):\n",
    "        self.name          = name       #a string\n",
    "        self.domain        = domain     #a list for string\n",
    "        self.father        = []         #a list\n",
    "        self.children      = []         #a list\n",
    "        self.pro_table     = {}         #init as an empty dict\n",
    "                                        #for example\n",
    "                                        #{(on,on):[0.1,0.9],(on,off):[0.2,0.8],(off,on):[0.3,0.7],(off,off):[0.4,0.6]}\n",
    "        \n",
    "    def add_father(self,fa):            #fa is a node\n",
    "        self.father.append(fa)\n",
    "        \n",
    "    def add_child(self,ch):             #ch is a node\n",
    "        self.children.append(ch)\n",
    "        \n",
    "    def add_pro(self,instance,table):   #instance is a string list, table is a float list\n",
    "        self.pro_table[instance] = table\n",
    "        \n",
    "class graph:\n",
    "    '''\n",
    "    The class to store a graph\n",
    "    The code will not check the validation of data, so please preprocess the data to ensure\n",
    "    1) there are heandings: name1,name2,...\n",
    "    2) no empty data\n",
    "    3) all data is discretized\n",
    "    4) last colum is the label\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.nodes         = []         #a list\n",
    "        \n",
    "    def get_node(self,the_node):\n",
    "        '''\n",
    "        functional function\n",
    "        get the node by name\n",
    "        input:\n",
    "            variable  type    description\n",
    "            ------------------------------\n",
    "            the_node, string, node name\n",
    "        output:\n",
    "            type         description\n",
    "            ------------------------------\n",
    "            class node,  the found node\n",
    "        '''\n",
    "        names              = [i.name for i in self.nodes]\n",
    "        node_index         = names.index(the_node)\n",
    "        return self.nodes[node_index]\n",
    "    \n",
    "    def get_node_index(self,the_node):\n",
    "        '''\n",
    "        functional function\n",
    "        get the node by name\n",
    "        input:\n",
    "            variable  type    description\n",
    "            ------------------------------\n",
    "            the_node, string, node name\n",
    "        output:\n",
    "            type         description\n",
    "            ------------------------------\n",
    "            int,         index\n",
    "        '''\n",
    "        names              = [i.name for i in self.nodes]\n",
    "        node_index         = names.index(the_node)\n",
    "        return node_index\n",
    "        \n",
    "    def add_node(self,name,domain):\n",
    "        '''\n",
    "        functional function\n",
    "        add a node by name and domain\n",
    "        input:\n",
    "            variable  type    description\n",
    "            ------------------------------\n",
    "            name,     string, node name\n",
    "            domain,   list,   domain of the node\n",
    "        '''\n",
    "        self.nodes.append(node(name,domain))\n",
    "        \n",
    "    def add_connection(self,from_node1,to_node2):#both from_node1 and to_node2 are strings\n",
    "        '''\n",
    "        functional function\n",
    "        add a connection betwen to nodes\n",
    "        input:\n",
    "            variable     type         description\n",
    "            -------------------------------------------\n",
    "            from_node1,  class node,  the first node\n",
    "            to_node2,    class node,  the second node\n",
    "        '''\n",
    "        from_node1         = self.get_node(from_node1)\n",
    "        to_node2           = self.get_node(to_node2)\n",
    "        \n",
    "        from_node1.add_child(to_node2)\n",
    "        to_node2.add_father(from_node1)\n",
    "        \n",
    "    def add_pro(self,the_node,instance,table):#the_node is a string\n",
    "        '''\n",
    "        functional function\n",
    "        add a conditioanal probability P(a|b) into a node\n",
    "        input:\n",
    "            variable  type    description\n",
    "            ------------------------------\n",
    "            the_node, string, node name\n",
    "            instance, list,   b part in P(a|b)\n",
    "                              where each entry in it is a value in domain\n",
    "            table,    list,   a part in P(a|b)\n",
    "                              where each entry in it is a probability responding to a value\n",
    "        '''\n",
    "        the_node           = self.get_node(the_node)\n",
    "        the_node.add_pro(instance,table)\n",
    "        \n",
    "    def get_nodes_from_data(self,headings,data):#headings = ['data1','data2',...], data = numpy 2d vector\n",
    "        '''\n",
    "        interface/functional function\n",
    "        get the basic information about node from data and insert them into the class\n",
    "        input:\n",
    "            variable  type            description\n",
    "            ------------------------------------------------\n",
    "            headings, numpy arrary,   the names of variables\n",
    "            data,     numpy 2darrary, all the data where row means different instance\n",
    "                                      and col means each sensor\n",
    "        '''\n",
    "        for i,name in enumerate(headings):\n",
    "            domain = list(set(data[:,i]))\n",
    "            self.add_node(name,domain)\n",
    "            \n",
    "    def mutual_information(self,data1,data2):\n",
    "        '''\n",
    "        functional function\n",
    "        get the mutual information between two cols\n",
    "        input:\n",
    "            variable  type            description\n",
    "            ------------------------------------------------\n",
    "            data1,    numpy arrary,   data of the first col\n",
    "            data2,    numpy arrary,   data of the second col\n",
    "        output:\n",
    "            type    description\n",
    "            -----------------------------\n",
    "            float,  mutual information entropy with laplace smooth\n",
    "        '''\n",
    "        assert(len(data1)==len(data2))\n",
    "        \n",
    "        mi       = 0.0\n",
    "        length   = len(data1)\n",
    "        \n",
    "        domain1 = list(set(data1))\n",
    "        domain2 = list(set(data2))\n",
    "        len1    = len(domain1)\n",
    "        len2    = len(domain2)\n",
    "        \n",
    "        for x in domain1:\n",
    "            for y in domain2:\n",
    "                Px     = float(data1.count(x) + 1)/(length+len1)    #laplace smooth\n",
    "                Py     = float(data2.count(y) + 1)/(length+len2)    #laplace smooth\n",
    "                \n",
    "                indexxy= [1 if (i==x)and(j==y) else 0 for i,j in zip(data1,data2)]\n",
    "                Pxy    = float(sum(indexxy) + 1)/(length+len1*len2) #laplace smooth\n",
    "                \n",
    "                mi     = mi + Pxy*math.log(Pxy/(Px*Py))\n",
    "        return mi\n",
    "    \n",
    "    def get_max_span_tree_prime(self,mi_dict):\n",
    "        '''\n",
    "        functional function\n",
    "        judge if some edges compose a span tree\n",
    "        input:\n",
    "            variable  type    description\n",
    "            -----------------------------\n",
    "            edges,    dict,   all the edges\n",
    "        output:\n",
    "            type    description\n",
    "            -----------------------------\n",
    "            set,    all the edges that compose a max span tree\n",
    "        '''\n",
    "        #prepare structure to qurey\n",
    "        Vnew  = set(max(mi_dict.items(),key=lambda d: d[1])[0][0])\n",
    "        V     = set()\n",
    "        Enew  = set()\n",
    "        edges  = defaultdict(list)\n",
    "        for i in mi_dict:\n",
    "            edges[i[0]].append(i[1])\n",
    "            edges[i[1]].append(i[0])\n",
    "            V.add(i[0])\n",
    "            V.add(i[1])\n",
    "        while Vnew != V:\n",
    "            new_edges = {}\n",
    "            for u in Vnew:\n",
    "                v = [i for i in edges[u] if i not in Vnew]\n",
    "                for vi in v:\n",
    "                    edge = (u,vi) if (u,vi) in mi_dict else (vi,u)\n",
    "                    new_edges[edge] = mi_dict[edge]\n",
    "            new_edges = sorted(new_edges.items(),key=lambda d:d[1],reverse = True)\n",
    "            best_edge = new_edges[0]\n",
    "            Enew.add(best_edge[0])\n",
    "            Vnew.add(best_edge[0][0])\n",
    "            Vnew.add(best_edge[0][1])\n",
    "        return Enew\n",
    "        \n",
    "        \n",
    "    def get_basic_tan_structure(self,headings,data):#headings = ['data1','data2',...], data = numpy 2d vector\n",
    "        '''\n",
    "        interface function\n",
    "        get the basic structure of TAN and connect the nodes in the class.\n",
    "        we assumpe that the last col is the label colum and is ignored when handle features\n",
    "        input:\n",
    "            variable  type            description\n",
    "            --------------------------------------------------\n",
    "            headings, numpy arrary,   names of variables/nodes\n",
    "            data,     numpy arrary,   all the monitor data\n",
    "        '''\n",
    "        #computing mutual information entropy between features\n",
    "        mi_dict = {}\n",
    "        for i in range(len(headings)-1):\n",
    "            for j in range(i+1,len(headings)-1):\n",
    "                data1   = data[:,i]\n",
    "                data2   = data[:,j]\n",
    "                mi      = self.mutual_information(data1,data2)\n",
    "                mi_dict[(headings[1],headings[2])] = mi\n",
    "        \n",
    "        #set maximal span tree, mst\n",
    "        mst             = self.get_max_span_tree_prime(mi_dict)\n",
    "        Visited         = set()\n",
    "        edges           = defaultdict(list)\n",
    "        for i in mst:\n",
    "            edges[i[0]].append(i[1])\n",
    "            edges[i[1]].append(i[0])\n",
    "        initial_node    = self.node[0].name\n",
    "        start           = [initial_node]\n",
    "        Visited.add(initial_node)\n",
    "        while len(start)!=0:\n",
    "            new_start = []\n",
    "            for i in start:\n",
    "                ends = edges[i]\n",
    "                for j in ends:\n",
    "                    if j not in Visited:\n",
    "                        Visited.add(j)\n",
    "                        new_start.append(j)\n",
    "                        self.add_connection(i,j)\n",
    "            start = new_start\n",
    "        \n",
    "        #set the connection between label and features\n",
    "        for i in range(len(self.nodes)-1):\n",
    "            self.add_connection(self.node[-1],self.node[i])\n",
    "            \n",
    "    def get_cpt(self,headings,data,node_name):\n",
    "        '''\n",
    "        interface/functional function\n",
    "        calculate the condition probability table based on the basic structure\n",
    "        input:\n",
    "            variable  type            description\n",
    "            --------------------------------------------------\n",
    "            headings, numpy arrary,   names of variables/nodes\n",
    "            data,     numpy arrary,   all the monitor data\n",
    "            node_name,string,         the node name\n",
    "        '''\n",
    "        the_index     = self.get_node_index(node_name)\n",
    "        the_node      = self.nodes[the_index]\n",
    "        father_nodes  = the_node.father\n",
    "        \n",
    "        domain_x = the_node.domain\n",
    "        data_x   = data[:,the_index]\n",
    "        len_x    = len(domain_x)\n",
    "        \n",
    "        length   = len(data)\n",
    "        \n",
    "        if len(father_nodes) == 0:\n",
    "            return\n",
    "        else if len(father_nodes)==1:#y-->x\n",
    "            domain_y = father_nodes[0].domain\n",
    "            data_y   = data[:,self.get_node_index(father_nodes[0].name)]\n",
    "            len_y    = len(domain_y)\n",
    "            \n",
    "            for y in domain_y:\n",
    "                table    = []\n",
    "                Py     = float(data_y.count(y) + 1)/(length+len_y)    #laplace smooth\n",
    "                for x in domain_x:\n",
    "                    indexxy= [1 if (i==x)and(j==y) else 0 for i,j in zip(data_x,data_y)]\n",
    "                    Pxy    = float(sum(indexxy) + 1)/(length+len_x*len_y) #laplace smooth\n",
    "                    table.append(float(Pxy)/Py)\n",
    "                self.add_pro(node_name,(y),table)\n",
    "                    \n",
    "        else if len(father_nodes)==2:\n",
    "            domain_y = father_nodes[0].domain\n",
    "            data_y   = data[:,self.get_node_index(father_nodes[0].name)]\n",
    "            len_y    = len(domain_y)\n",
    "            domain_z = father_nodes[1].domain\n",
    "            data_z   = data[:,self.get_node_index(father_nodes[1].name)]\n",
    "            len_z    = len(domain_z)\n",
    "            \n",
    "            for y in domain_y:\n",
    "                for z in domian_z:\n",
    "                    table = []\n",
    "                    indexyz= [1 if (i==y)and(j==z) else 0 for i,j in zip(data_y,data_z)]\n",
    "                    Pyz    = float(sum(indexyz) + 1)/(length+len_y*len_z) #laplace smooth\n",
    "                    for x in domain_x:\n",
    "                        indexxyz= [1 if (i==y)and(j==z)and(k==x) else 0 for i,j,k in zip(data_y,data_z,data_x)]\n",
    "                        Pxyz    = float(sum(indexxyz) + 1)/(length+len_y*len_z*len_x) #laplace smooth\n",
    "                        table.append(float(Pxyz)/Pyz)\n",
    "                    self.add_pro(node_name,(y,z),table)\n",
    "        else:\n",
    "            assert(len(father_nodes)<=2\n",
    "\n",
    "        \n",
    "    def train(self,headings,data):\n",
    "        '''\n",
    "        interface function\n",
    "        calculate the condition probability table based on the basic structure\n",
    "        input:\n",
    "            variable  type            description\n",
    "            --------------------------------------------------\n",
    "            headings, numpy arrary,   names of variables/nodes\n",
    "            data,     numpy arrary,   all the monitor data\n",
    "        '''\n",
    "        \n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
